{
  
    
        "post0": {
            "title": "Classifying Track Bikes Using Neural Networks",
            "content": "This notebook has various goals . document my initial attempts at using a CNN to classify track bikes. | demonstrates the use of fastai python library to quickly build the models. | demonstrates the use of fastpages to convert Jupyter notebooks into blog posts | . At the time of writing, please be aware of this bug and do not run v2.2.6 of the fastai library. . [ ] TODO settle on a consistent set of image transforms | . # folders=[&quot;aprilia&quot;, &quot;bmw&quot;, &quot;ducati&quot;, &quot;honda&quot;, &quot;kawasaki&quot;, # &quot;suzuki&quot;, &quot;triumph&quot;, &quot;yamha&quot;, &quot;nab&quot;]) # fns . All Makes Multi-Class Classfier . Loading and Preparing Data . Let us load our dataset . [ ] TODO Description of how the dataset was collected | . path_all_makes = Path(&quot;/home/nishan/Datasets/TrackBikes/&quot;) . . all_makes_db = DataBlock( blocks=(ImageBlock, CategoryBlock), get_items=get_image_files, splitter=RandomSplitter(valid_pct=0.3, seed=42), get_y=parent_label, item_tfms=Resize(128)) . all_makes_db.summary(path_all_makes) . Setting-up type transforms pipelines Collecting items from /home/nishan/Datasets/TrackBikes Found 386 items 2 datasets of sizes 271,115 Setting up Pipeline: PILBase.create Setting up Pipeline: parent_label -&gt; Categorize -- {&#39;vocab&#39;: None, &#39;sort&#39;: True, &#39;add_na&#39;: False} Building one sample Pipeline: PILBase.create starting from /home/nishan/Datasets/TrackBikes/suzuki/52854574_406475179899801_4611460463924871168_o.jpg applying PILBase.create gives PILImage mode=RGB size=2048x1365 Pipeline: parent_label -&gt; Categorize -- {&#39;vocab&#39;: None, &#39;sort&#39;: True, &#39;add_na&#39;: False} starting from /home/nishan/Datasets/TrackBikes/suzuki/52854574_406475179899801_4611460463924871168_o.jpg applying parent_label gives suzuki applying Categorize -- {&#39;vocab&#39;: None, &#39;sort&#39;: True, &#39;add_na&#39;: False} gives TensorCategory(6) Final sample: (PILImage mode=RGB size=2048x1365, TensorCategory(6)) Collecting items from /home/nishan/Datasets/TrackBikes Found 386 items 2 datasets of sizes 271,115 Setting up Pipeline: PILBase.create Setting up Pipeline: parent_label -&gt; Categorize -- {&#39;vocab&#39;: None, &#39;sort&#39;: True, &#39;add_na&#39;: False} Setting up after_item: Pipeline: Resize -- {&#39;size&#39;: (128, 128), &#39;method&#39;: &#39;crop&#39;, &#39;pad_mode&#39;: &#39;reflection&#39;, &#39;resamples&#39;: (2, 0), &#39;p&#39;: 1.0} -&gt; ToTensor Setting up before_batch: Pipeline: Setting up after_batch: Pipeline: IntToFloatTensor -- {&#39;div&#39;: 255.0, &#39;div_mask&#39;: 1} Building one batch Applying item_tfms to the first sample: Pipeline: Resize -- {&#39;size&#39;: (128, 128), &#39;method&#39;: &#39;crop&#39;, &#39;pad_mode&#39;: &#39;reflection&#39;, &#39;resamples&#39;: (2, 0), &#39;p&#39;: 1.0} -&gt; ToTensor starting from (PILImage mode=RGB size=2048x1365, TensorCategory(6)) applying Resize -- {&#39;size&#39;: (128, 128), &#39;method&#39;: &#39;crop&#39;, &#39;pad_mode&#39;: &#39;reflection&#39;, &#39;resamples&#39;: (2, 0), &#39;p&#39;: 1.0} gives (PILImage mode=RGB size=128x128, TensorCategory(6)) applying ToTensor gives (TensorImage of size 3x128x128, TensorCategory(6)) Adding the next 3 samples No before_batch transform to apply Collating items in a batch Applying batch_tfms to the batch built Pipeline: IntToFloatTensor -- {&#39;div&#39;: 255.0, &#39;div_mask&#39;: 1} starting from (TensorImage of size 4x3x128x128, TensorCategory([6, 2, 2, 5], device=&#39;cuda:0&#39;)) applying IntToFloatTensor -- {&#39;div&#39;: 255.0, &#39;div_mask&#39;: 1} gives (TensorImage of size 4x3x128x128, TensorCategory([6, 2, 2, 5], device=&#39;cuda:0&#39;)) . # all_makes_dsets.vocab . all_makes_dls = all_makes_db.dataloaders(path_all_makes) # dls.train.show_batch(max_n=4, nrows=1) . all_makes_dls.categorize.vocab . [&#39;aprilia&#39;, &#39;bmw&#39;, &#39;ducati&#39;, &#39;honda&#39;, &#39;kawasaki&#39;, &#39;not_a_bike&#39;, &#39;suzuki&#39;, &#39;triumph&#39;, &#39;yamaha&#39;] . we&#39;ve 9 classes. This is a multiclass problem. | [ ] TODO what is the breakdown of each class? | . all_makes_dls.show_batch() . as one can see this is a hard job, even veterans sometimes have a hard time :) | there is one exception, not_a_bike images are clearly distinct | . Training . learner_all_makes = cnn_learner(all_makes_dls, resnet18, metrics=[error_rate, F1Score(average=&quot;macro&quot;)], lr=0.001) learner_all_makes.fine_tune(10) . epoch train_loss valid_loss error_rate f1_score time . 0 | 3.364116 | 2.834197 | 0.747826 | 0.144764 | 00:06 | . epoch train_loss valid_loss error_rate f1_score time . 0 | 2.729491 | 2.448115 | 0.713043 | 0.177761 | 00:06 | . 1 | 2.459303 | 2.229129 | 0.669565 | 0.222884 | 00:07 | . 2 | 2.113288 | 2.158149 | 0.643478 | 0.227900 | 00:07 | . 3 | 1.864583 | 2.139234 | 0.626087 | 0.257213 | 00:06 | . 4 | 1.642238 | 2.135002 | 0.608696 | 0.273783 | 00:06 | . 5 | 1.437696 | 2.161934 | 0.600000 | 0.275873 | 00:06 | . 6 | 1.262745 | 2.146975 | 0.573913 | 0.314015 | 00:06 | . 7 | 1.116602 | 2.119561 | 0.565217 | 0.317892 | 00:06 | . 8 | 1.011884 | 2.110490 | 0.556522 | 0.326418 | 00:06 | . 9 | 0.912660 | 2.096010 | 0.556522 | 0.325116 | 00:06 | . the error_rate is actually increasing, the performance is getting worse with each epoch | the model is overfitting to the train set as the train_loss is decreasing | the performance metrics suck quite bad. This is not an acceptable model | . Evaluation . interp_all_bikes = ClassificationInterpretation.from_learner(learner_all_makes) . interp_all_bikes.print_classification_report() . precision recall f1-score support aprilia 0.60 0.60 0.60 5 bmw 0.09 0.17 0.12 6 ducati 0.00 0.00 0.00 3 honda 0.67 0.12 0.21 16 kawasaki 0.38 0.40 0.39 15 not_a_bike 0.89 1.00 0.94 17 suzuki 0.22 0.12 0.16 16 triumph 0.00 0.00 0.00 3 yamaha 0.44 0.59 0.51 34 accuracy 0.44 115 macro avg 0.37 0.33 0.33 115 weighted avg 0.47 0.44 0.42 115 . /home/nishan/anaconda3/envs/fastbook/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior. _warn_prf(average, modifier, msg_start, len(result)) /home/nishan/anaconda3/envs/fastbook/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior. _warn_prf(average, modifier, msg_start, len(result)) /home/nishan/anaconda3/envs/fastbook/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior. _warn_prf(average, modifier, msg_start, len(result)) . interp_all_bikes.plot_confusion_matrix(dpi=100) . the first thing to note is the lack of labelled data in the validation set for some classes for example, ducati has 3 images while yamaha has 34, bmw has 6 | this is an artificat of real life, as there are a lot more yamahas on the track | . | not_a_bike class does the best. this means the classifier has indeed figured out what constitutes a motorcycle. This could be because to train resnet, one class was actually motorcycle. | suzuki is often confused with yamaha | all the triumphs were mispredicted | . interp_all_bikes.plot_top_losses(12,) . interp_all_bikes.most_confused(2) . [(&#39;suzuki&#39;, &#39;yamaha&#39;, 9), (&#39;kawasaki&#39;, &#39;yamaha&#39;, 6), (&#39;bmw&#39;, &#39;yamaha&#39;, 4), (&#39;honda&#39;, &#39;kawasaki&#39;, 4), (&#39;honda&#39;, &#39;suzuki&#39;, 4), (&#39;yamaha&#39;, &#39;kawasaki&#39;, 4), (&#39;ducati&#39;, &#39;yamaha&#39;, 3), (&#39;honda&#39;, &#39;bmw&#39;, 3), (&#39;suzuki&#39;, &#39;bmw&#39;, 3), (&#39;yamaha&#39;, &#39;bmw&#39;, 3), (&#39;yamaha&#39;, &#39;suzuki&#39;, 3), (&#39;honda&#39;, &#39;ducati&#39;, 2), (&#39;kawasaki&#39;, &#39;ducati&#39;, 2), (&#39;triumph&#39;, &#39;yamaha&#39;, 2), (&#39;yamaha&#39;, &#39;not_a_bike&#39;, 2)] . Challenges in classification . lack of data | the rider adds unnecessary noise | different orientations of the bike | there are genuinely very few features from the bodywork that separate the makes | bike is not always center in the picture | make contains different models R6 R1 just in yamaha for example | . # doc(ClassificationInterpretation) # interp_all_bikes.preds # learner_all_makes.get_preds() # y_probs, y_preds = learner_all_makes.get_preds(dl=dls_all_makes.valid) # y_probs # y_preds # dls_all_makes.valid.vocab # y_preds.where(y_preds == 4, torch.scalar_tensor(0)) # torch.scalar_tensor(0,) # dls_all_makes.valid.categorize? # dls_all_makes.valid.items . Yamaha or Not Multi-Class Classifier . We now try an easier problem, is the trackbike a {Yamaha, Not a Yamaha, Not a bike} . path_yamaha_binary = Path(&quot;/home/nishan/Datasets/YamahaBinary/&quot;) . yamaha_binary_db = DataBlock( blocks=(ImageBlock, CategoryBlock), get_items=get_image_files, splitter=RandomSplitter(valid_pct=0.2, seed=42), get_y=parent_label, item_tfms=Resize(128)) # other possible datablocks. Mainly they differ in the transforms applied to the images # bikes = DataBlock( # blocks=(ImageBlock, CategoryBlock), # get_items=get_image_files, # splitter=None, # get_y=parent_label, # item_tfms=Resize(128)) # bikes = bikes.new( # item_tfms=RandomResizedCrop(224, min_scale=0.5), # batch_tfms=aug_transforms()) # bikes = bikes.new( # item_tfms=RandomResizedCrop(224, min_scale=0.5), # batch_tfms=None) # dls = bikes.dataloaders(path_trackbikes) # bikes = bikes.new( # item_tfms=Resize(224, ResizeMethod.Squish), # batch_tfms=aug_transforms()) # bikes = bikes.new( # item_tfms=Resize(224, ResizeMethod.Pad, pad_mode=&#39;zeros&#39;), # batch_tfms=None) . yamaha_binary_dls = yamaha_binary_db.dataloaders(path_yamaha_binary) . yamaha_binary_dls.show_batch(max_n=6, nrows=2) . you can see that the cropping sometimes takes out the bike from the image | . # dls = bikes.dataloaders(path_trackbikes) # dls.train.show_batch(max_n=8, nrows=2, unique=True) . # item_tfms=Resize(224, ResizeMethod.Pad, pad_mode=&#39;zeros&#39;), # batch_tfms=None) # dls = bikes.dataloaders(path_trackbikes) # dls.train.show_batch(max_n=4, nrows=1, unique=True) . Train . learner_yamaha_binary = cnn_learner(yamaha_binary_dls, resnet18, metrics=[error_rate, F1Score(average=&quot;macro&quot;)], lr=0.001) learner_yamaha_binary.fine_tune(10) . epoch train_loss valid_loss error_rate f1_score time . 0 | 1.768223 | 1.144281 | 0.362637 | 0.603333 | 00:07 | . epoch train_loss valid_loss error_rate f1_score time . 0 | 1.418883 | 0.790680 | 0.285714 | 0.739029 | 00:07 | . 1 | 1.273870 | 0.645831 | 0.274725 | 0.737172 | 00:07 | . 2 | 1.151472 | 0.568919 | 0.208791 | 0.811558 | 00:07 | . 3 | 0.993393 | 0.602356 | 0.219780 | 0.803774 | 00:07 | . 4 | 0.848403 | 0.645509 | 0.263736 | 0.753360 | 00:07 | . 5 | 0.740083 | 0.648150 | 0.285714 | 0.730102 | 00:07 | . 6 | 0.661264 | 0.660848 | 0.274725 | 0.743106 | 00:07 | . 7 | 0.577748 | 0.672199 | 0.241758 | 0.779887 | 00:07 | . 8 | 0.525509 | 0.663386 | 0.219780 | 0.799369 | 00:07 | . 9 | 0.478367 | 0.661577 | 0.219780 | 0.799369 | 00:07 | . resnet18 lr=0.001, fine_tune 10 error_rate 0.480519 and decreasing | lr=0.01 fine_tune=10, error_rate=0.467532 and stagnating | lr=0.001, fine_tune=20, error_rate=0.454545 and oscillating around this. train loss slightly decreasing, valid loss oscillating | lr=0.0005, fine_tune=20, error_rate=0.415584 and oscillating. valid_loss also oscillaing around 1.555 | . | resnet34 . lr=0.001, fine_tune=20, error_rate=0.480519 and stagnant | . | all the above numbers are when not_a_bike is included . | how was it so good before? because not_a_bike class was included in training? | its something to do train and valid folders and what&#39;s in there? | . | without not_a_bike class 0.62-0.64 error_rate | . | using the train and valid folders only and skipping the RandomSplitter 0.716667 error_rate after 10 epochs | . | no aug_tfms when in batch 0.566667 | after various tries, to get an error_rate &lt; 0.5 with so many track bike brands is really hard | . yamaha or not . resnet18 0.4 error_rate | resnet 50 0.31 after 20 epochs | . | yamaha or not and not a bike . resnet 50 0.25 after 50 epochs | resent 128 0.3 after 20 epochs | batch_tfms=aug_transforms(mult=2) from 1--&gt;2 gives 0.274725 and a slightly higher f1 score 0.76. looks like it has helped a bit | . | . Evaluate . interp_yamaha_binary = ClassificationInterpretation.from_learner(learner_yamaha_binary) . interp_yamaha_binary.plot_confusion_matrix(dpi=100) . interp_yamaha_binary.print_classification_report() . precision recall f1-score support not_a_bike 0.93 1.00 0.96 13 not_yamaha 0.79 0.82 0.81 51 yamaha 0.67 0.59 0.63 27 accuracy 0.78 91 macro avg 0.80 0.81 0.80 91 weighted avg 0.77 0.78 0.78 91 . its still challenging to predict a yamaha for a yamaha. | not a bike class is the easiest and brings up the avaerged f1 score. | not_yamaha precision is acceptable | . interp_yamaha_binary.plot_top_losses(6, nrows=2) . the nn is associating green with kawasaki, which is good but there are r6s that are green | would a grayscale transform help? | . Conclusion and Future Work .",
            "url": "https://nahsin.github.io/musings/fastpages/jupyter/2021/03/22/Classifying-Track-Bikes.html",
            "relUrl": "/fastpages/jupyter/2021/03/22/Classifying-Track-Bikes.html",
            "date": " • Mar 22, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Math Equations Support",
            "content": "Corolla vs Ferrari . Imagine racing your car against an F1 car. Your car has speed $100~km/h$ while the F1 car has speed //(300~km/h ). The race director decides to show mercy and gives your car a head start. How long will it take for the F1 car to catch up to you? . Denote $t_0$ as the head start given to your car. Your car travels a distance $d$ as, begin{equation} label{eq:car} d = 100t, end{equation} . and the F1 car will travel that same distance as, begin{equation} label{eq:f1} d = 300(t - t_0). end{equation} . Substituting eqref{eq:car} into eqref{eq:f1} and solving for $t$ gives begin{aligned} 100t &amp;= 300(t - t_0), 200t &amp;= 300t_0, label{eq:t} t &amp;= frac{3}{2}t_0. end{aligned} . Now, let’s do a drag race! Let the drag strip be a $1~km$ long straight. What is the head start your car requires to tie or win the race? . Substituting eqref{eq:t} into eqref{eq:car}, we’ve begin{equation} label{eq:d} d = 150t_0. end{equation} We plug in the numbers to get $t_0 = 1/150~h = 24~s$. Therefore, your car needs to have a head start of at least $24~s$ to tie or win. .",
            "url": "https://nahsin.github.io/musings/2020/05/17/math-equations-support.html",
            "relUrl": "/2020/05/17/math-equations-support.html",
            "date": " • May 17, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://nahsin.github.io/musings/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://nahsin.github.io/musings/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "Stop ssh/sshfs from hanging up your applications",
            "content": "For my work, I need to keep multiple ssh and sshfs tunnels open. After an upgrade to Ubuntu 16.04, my ssh tunnels started to hang after some period of inactivity. Now if a ssh tunnel hangs, all one has to do is close the terminal. So inconvenient but managable. But if a sshfs tunnel hangs, then a simple ls command can hang the terminal. Or if you are using Nautilus (file manager), simply trying to browse to the mounted folder will cause a hang making you force quit the application. Lastly, desperation kicks in and you now try to force a umount, but OS will complain saying some resource is busy. To summarize, I am forced to restart every time a sshfs tunnel hangs which is really annoying. . To resolve this issue for ssh, we use the option ServerAliveInterval. Quoting from the man page of ssh_config, . ServerAliveInterval Sets a timeout interval in seconds after which if no data has been received from the server, ssh(1) will send a message through the encrypted channel to request a response from the server. The default is 0, indicating that these messages will not be sent to the server, or 300 if the BatchMode option is set. ProtocolKeepAlives and SetupTimeOut are Debian-specific compati- bility aliases for this option. . Therefore, either modify your ssh_config file or use the following command . ssh -o ServerAliveInterval=300 user@machine-name . So far, 300 = 5 minutes has served me well. Experiment with the value to find one that works for you. . For sshfs, use the following command . sshfs user@machine-name -o ServerAliveInterval=300 mount-path .",
            "url": "https://nahsin.github.io/musings/2016/05/22/ssh-sshfs-stop-hanging.html",
            "relUrl": "/2016/05/22/ssh-sshfs-stop-hanging.html",
            "date": " • May 22, 2016"
        }
        
    
  
    
        ,"post5": {
            "title": "Google Now vs Siri",
            "content": "So when it comes to artificial intelligence, who is smarter, Apple’s Siri or Google Now? There are two components to this question; voice/language recognition and data mining. As one might expect, Google is the clear winner in the data mining category. But as the following list of questions shows, Google Now also possess vastly superior voice recognition traits. On the other hand, Siri could not even understand most of these questions by voice, and even if it did or I typed them, the result was a simple Bing search. So try them out yourself. . Who is the queen of Jordan? | Status of flight 9W229 | Who is Manmohan Singh? | When was Manmohan Singh the finance minister of India? | Who is Guru Gobind Singh? | What is Sikhism? | Who was the third guru of Sikhism? | Birthday of Nehru? | When did the US gain it’s independence from Britain? | When did Angela Merkel become the Chancellor of Germany? | How long did the British rule India? | . Now one can argue that Siri is not really meant for yielding useful information. It’s only good for calling, sending messages, setting reminders and answering stupid questions with stupid answers at a party. But except the last mundane point, Google Now also does the same job but way better. So as it stands now, sorry Siri, you suck and I really miss my Nexus 4 :(. Oh I should also mention, Google Now has way more spoken languages than Siri including English (India) complete with best Indian accent I have heard from a machine. . Lastly, if you got thirty minutes to spare, watch this video comparison between Google Now, Siri and Cortana. . Peace out, . Nishan .",
            "url": "https://nahsin.github.io/musings/2015/12/13/siri-vs-googlenow.html",
            "relUrl": "/2015/12/13/siri-vs-googlenow.html",
            "date": " • Dec 13, 2015"
        }
        
    
  
    
        ,"post6": {
            "title": "First Post",
            "content": "As tradition dictates for a first post, . Hello World! . print ‘Hello World!’ . printf(“Hello World!”) . write(6,*) “Hello World” .",
            "url": "https://nahsin.github.io/musings/2015/12/13/first-post.html",
            "relUrl": "/2015/12/13/first-post.html",
            "date": " • Dec 13, 2015"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://nahsin.github.io/musings/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://nahsin.github.io/musings/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}